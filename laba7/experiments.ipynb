{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import enjoyml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.85\n",
    "set_session(tf.Session(config=config))\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers, callbacks, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 28479.80it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 29339.63it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 27805.50it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 28409.10it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/aclImdb/'\n",
    "\n",
    "def read_data(data_path):\n",
    "    sentences, labels = [], []\n",
    "    dir_label_to_int = {'neg/': 0 , 'pos/': 1}\n",
    "    for dir_label in dir_label_to_int.keys():  \n",
    "        data_label_path  = data_path + dir_label\n",
    "        label = dir_label_to_int[dir_label]\n",
    "        for file_name in tqdm(os.listdir(data_label_path)):\n",
    "            with open(data_label_path + file_name, 'r+') as data_file:\n",
    "                sentense = data_file.read()\n",
    "                sentences.append(sentense), labels.append(label)\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "train_sentences, train_labels = read_data(DATA_PATH + 'train/')\n",
    "test_sentences, test_labels = read_data(DATA_PATH + 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aafdsa', 'faafads', 'fsdaf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'aafdsa  faafads    fsdaf   '.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:03<00:00, 7802.21it/s]\n",
      "100%|██████████| 25000/25000 [00:03<00:00, 8289.27it/s]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_PATH = DATA_PATH + 'imdb.vocab'\n",
    "\n",
    "vocab_encode_dict = {}\n",
    "with open(VOCAB_PATH, 'r+') as vocab_file:\n",
    "    for i, token_line in enumerate(vocab_file):\n",
    "        token = token_line.replace('\\n', '')\n",
    "        vocab_encode_dict[token] = i\n",
    "\n",
    "\n",
    "filter_tokens=('?', '.', ',', '!', '<br>', '<br/>', \n",
    "               '\\'', '\"', '(', ')', '<br', '/>', ';', \n",
    "               ':', '-')\n",
    "\n",
    "def replace_chars(s, replaced_chars, new_char):\n",
    "    for char in replaced_chars:\n",
    "        s = s.replace(char, new_char)\n",
    "    return s\n",
    "\n",
    "def encode_with_vocab(sentences, filter_tokens=filter_tokens, verbosity=0):\n",
    "    sentences_encoded = []\n",
    "    for sentense in tqdm(sentences):\n",
    "        tokens = replace_chars(sentense, filter_tokens, ' ').split()\n",
    "        tokens_encoded = []\n",
    "        for token in tokens:\n",
    "            token = token.lower()\n",
    "            if token in vocab_encode_dict:\n",
    "                tokens_encoded.append(vocab_encode_dict[token])\n",
    "            elif verbosity:\n",
    "                print(token)\n",
    "        sentences_encoded.append(tokens_encoded)\n",
    "    return sentences_encoded\n",
    "\n",
    "train_sentences_encoded = encode_with_vocab(train_sentences) # , verbosity=1\n",
    "test_sentences_encoded = encode_with_vocab(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89527"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_encode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATGUlEQVR4nO3df4xdZ33n8fdnnSaqKCgOmVqunawNayoF1JowCpEWULZZEies6lBVrP1H49IIg0ikot3V1ln+SEQ3UuiWIkViU5nFwqloTLYhGwucDcZiG63UgCfgOnYgeGIcZSzHnsYs6S5V2tDv/nGfqQ5mZjwz93rGM/N+SVf3nO95zjnPM8fjj8+Pe52qQpK0vP2zhe6AJGnhGQaSJMNAkmQYSJIwDCRJwCUL3YG5uvLKK2vdunUL3Q1JWlSeeeaZv6mqoXPrizYM1q1bx8jIyEJ3Q5IWlSQvTlb3MpEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEliBmGQZFeSM0mOdGpfTnKovU4kOdTq65L8XWfZn3bWeVeSZ5OMJnkgSVr9iiT7kxxr7ysvxEAlSVObyZnBF4FN3UJV/duq2lhVG4FHga90Fr8wsayqPtapPwh8BNjQXhPb3AEcqKoNwIE2L0maR+f9BHJVPZVk3WTL2r/uPwT8xnTbSLIaeFNVPd3mHwJuA54ANgM3tKa7gf8F/MFMOj9X63Z87UJufkon7v/AguxXks6n33sG7wVOV9WxTm19ku8m+csk7221NcBYp81YqwGsqqpTbfplYFWffZIkzVK/3020FXi4M38KuLqqXknyLuB/JHn7TDdWVZVkyv+HM8l2YDvA1VdfPccuS5LONeczgySXAL8FfHmiVlWvVdUrbfoZ4AXgbcBJYG1n9bWtBnC6XUaauJx0Zqp9VtXOqhququGhoZ/70j1J0hz1c5noXwPfr6p/uvyTZCjJijb9Fno3io+3y0CvJrm+3We4HXi8rbYX2Namt3XqkqR5MpNHSx8G/gr41SRjSe5oi7bws5eIAN4HHG6Pmv4F8LGqOtuWfRz4b8AovTOGJ1r9fuD9SY7RC5j7+xiPJGkOZvI00dYp6r87Se1Reo+aTtZ+BHjHJPVXgBvP1w9J0oXjJ5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJzCAMkuxKcibJkU7t3iQnkxxqr1s7y+5OMprk+SQ3d+qbWm00yY5OfX2Sb7X6l5NcOsgBSpLObyZnBl8ENk1S/2xVbWyvfQBJrgG2AG9v6/zXJCuSrAA+B9wCXANsbW0BPt229S+AHwF39DMgSdLsnTcMquop4OwMt7cZ2FNVr1XVD4FR4Lr2Gq2q41X198AeYHOSAL8B/EVbfzdw2yzHIEnqUz/3DO5KcrhdRlrZamuAlzptxlptqvqbgf9TVa+fU59Uku1JRpKMjI+P99F1SVLXXMPgQeCtwEbgFPCZgfVoGlW1s6qGq2p4aGhoPnYpScvCJXNZqapOT0wn+Tzw1TZ7Eriq03RtqzFF/RXg8iSXtLODbntJ0jyZ05lBktWd2Q8CE08a7QW2JLksyXpgA/Bt4CCwoT05dCm9m8x7q6qAbwK/3dbfBjw+lz5JkubuvGcGSR4GbgCuTDIG3APckGQjUMAJ4KMAVXU0ySPAc8DrwJ1V9dO2nbuAJ4EVwK6qOtp28QfAniT/Gfgu8IWBjU6SNCPnDYOq2jpJecq/sKvqPuC+Ser7gH2T1I/Te9pIkrRA/ASyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSMwiDJLuSnElypFP7L0m+n+RwkseSXN7q65L8XZJD7fWnnXXeleTZJKNJHkiSVr8iyf4kx9r7ygsxUEnS1GZyZvBFYNM5tf3AO6rq14AfAHd3lr1QVRvb62Od+oPAR4AN7TWxzR3AgaraABxo85KkeXTeMKiqp4Cz59S+XlWvt9mngbXTbSPJauBNVfV0VRXwEHBbW7wZ2N2md3fqkqR5Moh7Br8HPNGZX5/ku0n+Msl7W20NMNZpM9ZqAKuq6lSbfhlYNdWOkmxPMpJkZHx8fABdlyRBn2GQ5JPA68CXWukUcHVVvRP4d8CfJ3nTTLfXzhpqmuU7q2q4qoaHhob66LkkqeuSua6Y5HeBfwPc2P4Sp6peA15r088keQF4G3CSn72UtLbVAE4nWV1Vp9rlpDNz7ZMkaW7mdGaQZBPwH4HfrKqfdOpDSVa06bfQu1F8vF0GejXJ9e0potuBx9tqe4FtbXpbpy5JmifnPTNI8jBwA3BlkjHgHnpPD10G7G9PiD7dnhx6H/CpJP8A/CPwsaqauPn8cXpPJv0ivXsME/cZ7gceSXIH8CLwoYGMTJI0Y+cNg6raOkn5C1O0fRR4dIplI8A7Jqm/Atx4vn5Iki4cP4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEDMMgya4kZ5Ic6dSuSLI/ybH2vrLVk+SBJKNJDie5trPOttb+WJJtnfq7kjzb1nkgSQY5SEnS9GZ6ZvBFYNM5tR3AgaraABxo8wC3ABvaazvwIPTCA7gHeDdwHXDPRIC0Nh/prHfuviRJF9CMwqCqngLOnlPeDOxu07uB2zr1h6rnaeDyJKuBm4H9VXW2qn4E7Ac2tWVvqqqnq6qAhzrbkiTNg37uGayqqlNt+mVgVZteA7zUaTfWatPVxyap/5wk25OMJBkZHx/vo+uSpK6B3EBu/6KvQWzrPPvZWVXDVTU8NDR0oXcnSctGP2Fwul3iob2fafWTwFWddmtbbbr62knqkqR50k8Y7AUmngjaBjzeqd/eniq6Hvhxu5z0JHBTkpXtxvFNwJNt2atJrm9PEd3e2ZYkaR5cMpNGSR4GbgCuTDJG76mg+4FHktwBvAh8qDXfB9wKjAI/AT4MUFVnk/whcLC1+1RVTdyU/ji9J5Z+EXiivSRJ82RGYVBVW6dYdOMkbQu4c4rt7AJ2TVIfAd4xk75IkgbPTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6CMMkvxqkkOd16tJPpHk3iQnO/VbO+vcnWQ0yfNJbu7UN7XaaJId/Q5KkjQ7l8x1xap6HtgIkGQFcBJ4DPgw8Nmq+uNu+yTXAFuAtwO/Anwjydva4s8B7wfGgINJ9lbVc3PtmyRpduYcBue4EXihql5MMlWbzcCeqnoN+GGSUeC6tmy0qo4DJNnT2hoGkjRPBnXPYAvwcGf+riSHk+xKsrLV1gAvddqMtdpU9Z+TZHuSkSQj4+PjA+q6JKnvMEhyKfCbwH9vpQeBt9K7hHQK+Ey/+5hQVTurariqhoeGhga1WUla9gZxmegW4DtVdRpg4h0gyeeBr7bZk8BVnfXWthrT1CVJ82AQl4m20rlElGR1Z9kHgSNtei+wJcllSdYDG4BvAweBDUnWt7OMLa2tJGme9HVmkOQN9J4C+min/EdJNgIFnJhYVlVHkzxC78bw68CdVfXTtp27gCeBFcCuqjraT78kSbPTVxhU1f8D3nxO7XemaX8fcN8k9X3Avn76IkmaOz+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJPv8PZM3Ouh1fW7B9n7j/Awu2b0kXv77PDJKcSPJskkNJRlrtiiT7kxxr7ytbPUkeSDKa5HCSazvb2dbaH0uyrd9+SZJmblCXif5VVW2squE2vwM4UFUbgANtHuAWYEN7bQcehF54APcA7wauA+6ZCBBJ0oV3oe4ZbAZ2t+ndwG2d+kPV8zRweZLVwM3A/qo6W1U/AvYDmy5Q3yRJ5xhEGBTw9STPJNneaquq6lSbfhlY1abXAC911h1rtanqPyPJ9iQjSUbGx8cH0HVJEgzmBvJ7qupkkl8G9if5fndhVVWSGsB+qKqdwE6A4eHhgWxTkjSAM4OqOtnezwCP0bvmf7pd/qG9n2nNTwJXdVZf22pT1SVJ86CvMEjyhiRvnJgGbgKOAHuBiSeCtgGPt+m9wO3tqaLrgR+3y0lPAjclWdluHN/UapKkedDvZaJVwGNJJrb151X1P5McBB5JcgfwIvCh1n4fcCswCvwE+DBAVZ1N8ofAwdbuU1V1ts++SZJmqK8wqKrjwK9PUn8FuHGSegF3TrGtXcCufvojSZobv45CkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJPsIgyVVJvpnkuSRHk/x+q9+b5GSSQ+11a2edu5OMJnk+yc2d+qZWG02yo78hSZJm65I+1n0d+PdV9Z0kbwSeSbK/LftsVf1xt3GSa4AtwNuBXwG+keRtbfHngPcDY8DBJHur6rk++iZJmoU5h0FVnQJOtem/TfI9YM00q2wG9lTVa8APk4wC17Vlo1V1HCDJntbWMJCkeTKQewZJ1gHvBL7VSnclOZxkV5KVrbYGeKmz2lirTVWfbD/bk4wkGRkfHx9E1yVJDCAMkvwS8Cjwiap6FXgQeCuwkd6Zw2f63ceEqtpZVcNVNTw0NDSozUrSstfPPQOS/AK9IPhSVX0FoKpOd5Z/Hvhqmz0JXNVZfW2rMU1dkjQP+nmaKMAXgO9V1Z906qs7zT4IHGnTe4EtSS5Lsh7YAHwbOAhsSLI+yaX0bjLvnWu/JEmz18+Zwb8Efgd4NsmhVvtPwNYkG4ECTgAfBaiqo0keoXdj+HXgzqr6KUCSu4AngRXArqo62ke/JEmz1M/TRP8byCSL9k2zzn3AfZPU9023niTpwvITyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJJEn99NpMVj3Y6vLch+T9z/gQXZr6TZ8cxAkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn4CWRdYAv1yWfw08/SbHhmIEkyDCRJF1EYJNmU5Pkko0l2LHR/JGk5uSjCIMkK4HPALcA1wNYk1yxsryRp+bhYbiBfB4xW1XGAJHuAzcBzC9orLWp+bbc0cxdLGKwBXurMjwHvPrdRku3A9jb7f5M8P4d9XQn8zRzWW8yW45hhgcadT8/3Hn/GcjzWy3HMMPdx//PJihdLGMxIVe0EdvazjSQjVTU8oC4tCstxzLA8x+2Yl49Bj/uiuGcAnASu6syvbTVJ0jy4WMLgILAhyfoklwJbgL0L3CdJWjYuistEVfV6kruAJ4EVwK6qOnqBdtfXZaZFajmOGZbnuB3z8jHQcaeqBrk9SdIidLFcJpIkLSDDQJK0fMJgqX/dRZITSZ5NcijJSKtdkWR/kmPtfWWrJ8kD7WdxOMm1C9v7mUmyK8mZJEc6tVmPMcm21v5Ykm0LMZbZmGLc9yY52Y73oSS3dpbd3cb9fJKbO/VF8zuQ5Kok30zyXJKjSX6/1Zfs8Z5mzPNzrKtqyb/o3ZR+AXgLcCnw18A1C92vAY/xBHDlObU/Ana06R3Ap9v0rcATQIDrgW8tdP9nOMb3AdcCR+Y6RuAK4Hh7X9mmVy702OYw7nuB/zBJ22van+/LgPXtz/2KxfY7AKwGrm3TbwR+0Ma2ZI/3NGOel2O9XM4M/unrLqrq74GJr7tY6jYDu9v0buC2Tv2h6nkauDzJ6oXo4GxU1VPA2XPKsx3jzcD+qjpbVT8C9gObLnzv526KcU9lM7Cnql6rqh8Co/T+/C+q34GqOlVV32nTfwt8j943FSzZ4z3NmKcy0GO9XMJgsq+7mO6HvBgV8PUkz7Sv7QBYVVWn2vTLwKo2vZR+HrMd41Ia+13tksiuicslLMFxJ1kHvBP4FsvkeJ8zZpiHY71cwmA5eE9VXUvvm1/vTPK+7sLqnVcu6eeIl8MYOx4E3gpsBE4Bn1nY7lwYSX4JeBT4RFW92l22VI/3JGOel2O9XMJgyX/dRVWdbO9ngMfonSqenrj8097PtOZL6ecx2zEuibFX1emq+mlV/SPweXrHG5bQuJP8Ar2/FL9UVV9p5SV9vCcb83wd6+USBkv66y6SvCHJGyemgZuAI/TGOPH0xDbg8Ta9F7i9PYFxPfDjzqn3YjPbMT4J3JRkZTvdvqnVFpVz7vF8kN7xht64tyS5LMl6YAPwbRbZ70CSAF8AvldVf9JZtGSP91RjnrdjvdB30OfrRe9pgx/Qu8v+yYXuz4DH9hZ6Twz8NXB0YnzAm4EDwDHgG8AVrR56/5nQC8CzwPBCj2GG43yY3mnyP9C7DnrHXMYI/B69m22jwIcXelxzHPeftXEdbr/oqzvtP9nG/TxwS6e+aH4HgPfQuwR0GDjUXrcu5eM9zZjn5Vj7dRSSpGVzmUiSNA3DQJJkGEiSDANJEoaBJAnDQJKEYSBJAv4/4OFNIPEWHHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(lambda sents: len(sents), train_sentences_encoded)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_sentences_encoded_padded = pad_sequences(train_sentences_encoded, maxlen=500,\n",
    "                                               padding='post', truncating='post')\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_sentences_encoded_padded = pad_sequences(test_sentences_encoded, maxlen=500,\n",
    "                                              padding='post', truncating='post')\n",
    "test_labels = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences_encoded_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = np.arange(train_labels.shape[0])\n",
    "np.random.shuffle(train_indexes)\n",
    "train_sentences_encoded_padded = train_sentences_encoded_padded[train_indexes]\n",
    "train_labels = train_labels[train_indexes]\n",
    "\n",
    "test_indexes = np.arange(test_labels.shape[0])\n",
    "np.random.shuffle(test_indexes)\n",
    "test_sentences_encoded_padded = test_sentences_encoded_padded[test_indexes]\n",
    "test_labels = test_labels[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indixes, val_indexes = train_test_split(np.arange(work_features_matrix.shape[0]), \n",
    "#                                               test_size=0.07, stratify=work_labels, random_state=42)\n",
    "# # train_indixes, val_indexes = train_test_split(np.arange(work_features_matrix.shape[0]), \n",
    "# #                                               test_size=0.50, stratify=work_labels, random_state=42)\n",
    "\n",
    "# print(train_indixes.shape, val_indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_model_full = get_fc_model(28)\n",
    "\n",
    "# fc_model_full.compile(loss='sparse_categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# lr_reducer = callbacks.ReduceLROnPlateau(monitor='loss', factor=5e-2, patience=3, \n",
    "#                                          min_lr=1e-15, min_delta=0.03, verbose=1)\n",
    "# stopper = callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=10, \n",
    "#                                   verbose=1, restore_best_weights=True)\n",
    "\n",
    "# fc_model_full.fit(work_features_matrix/255, work_labels_encoded,\n",
    "#                   batch_size=256, epochs=150,\n",
    "#                   callbacks=[lr_reducer, stopper])\n",
    "\n",
    "# fc_model.fit(train_features_matrix/255, train_labels_encoded,\n",
    "#              batch_size=256, epochs=150,\n",
    "#              validation_data=(val_features_matrix/255, val_labels_encoded),\n",
    "#              callbacks=[lr_reducer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекурентная сеть с векторизацией через индекс в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 64)          6528      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               49536     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 105,601\n",
      "Trainable params: 105,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    x = input_ = layers.Input((None, 1,))\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(32, dropout=0.2,\n",
    "                                        return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(64, dropout=0.2,))(x)\n",
    "    \n",
    "#     x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizers.RMSprop(), loss='binary_crossentropy', metrics=['acc']) # lr=1e-4\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/20\n",
      "21250/21250 [==============================] - 90s 4ms/step - loss: 0.6934 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.5040\n",
      "Epoch 2/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.6932 - acc: 0.5072 - val_loss: 0.6968 - val_acc: 0.5021\n",
      "Epoch 3/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.6934 - acc: 0.5048 - val_loss: 0.6929 - val_acc: 0.5032\n",
      "Epoch 4/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.6934 - acc: 0.5029 - val_loss: 0.6930 - val_acc: 0.5032\n",
      "Epoch 5/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.6932 - acc: 0.5048 - val_loss: 0.6930 - val_acc: 0.5032\n",
      "Epoch 6/20\n",
      " 6400/21250 [========>.....................] - ETA: 53s - loss: 0.6931 - acc: 0.5097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bf9c3f7fab9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sentences_encoded_padded[:, :, np.newaxis]/len(vocab_encode_dict), train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 186s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932748725128174, 0.5008800029754639]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded[:, :, np.newaxis]/len(vocab_encode_dict), test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекурентная сеть с обучаемым эмбедингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 8)           716216    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, None, 32)          2400      \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 64)                12480     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 751,865\n",
      "Trainable params: 751,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    x = input_ = layers.Input((None,))\n",
    "    \n",
    "    x = layers.Embedding(len(vocab_encode_dict), 8)(x) #\n",
    "    x = layers.Bidirectional(layers.GRU(16, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(32))(x)\n",
    "    \n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) # lr=1e-4\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/4\n",
      "21250/21250 [==============================] - 85s 4ms/step - loss: 0.6688 - accuracy: 0.5746 - val_loss: 0.5443 - val_accuracy: 0.7328\n",
      "Epoch 2/4\n",
      "21250/21250 [==============================] - 83s 4ms/step - loss: 0.4030 - accuracy: 0.8306 - val_loss: 0.3928 - val_accuracy: 0.8325\n",
      "Epoch 3/4\n",
      "21250/21250 [==============================] - 84s 4ms/step - loss: 0.2578 - accuracy: 0.9103 - val_loss: 0.3916 - val_accuracy: 0.8456\n",
      "Epoch 4/4\n",
      "21250/21250 [==============================] - 83s 4ms/step - loss: 0.1492 - accuracy: 0.9511 - val_loss: 0.4223 - val_accuracy: 0.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f062b08c780>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sentences_encoded_padded, train_labels,\n",
    "    epochs=4,\n",
    "    batch_size=256,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 185s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5142109258317947, 0.8200799822807312]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная сеть с обучаемым эмбедингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 500, 16)           1432432   \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 494, 32)           3616      \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 488, 32)           7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 162, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 156, 64)           14400     \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 150, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,306,097\n",
      "Trainable params: 2,306,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    x = input_ = layers.Input((500,))\n",
    "    \n",
    "    x = layers.Embedding(len(vocab_encode_dict), 16)(x)\n",
    "    \n",
    "    x = layers.Conv1D(32, 7, activation='relu')(x)\n",
    "    x = layers.Conv1D(32, 7, activation='relu')(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, 7, activation='relu')(x)\n",
    "    x = layers.Conv1D(64, 7, activation='relu')(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "        \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc']) # lr=1e-4\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/30\n",
      "21250/21250 [==============================] - 2s 116us/step - loss: 0.6930 - acc: 0.5113 - val_loss: 0.6933 - val_acc: 0.5061\n",
      "Epoch 2/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.6925 - acc: 0.5171 - val_loss: 0.6927 - val_acc: 0.5147\n",
      "Epoch 3/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.6914 - acc: 0.5279 - val_loss: 0.6934 - val_acc: 0.4992\n",
      "Epoch 4/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.6670 - acc: 0.6077 - val_loss: 0.7229 - val_acc: 0.5181\n",
      "Epoch 5/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.5636 - acc: 0.7185 - val_loss: 0.6056 - val_acc: 0.6672\n",
      "Epoch 6/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.4630 - acc: 0.7866 - val_loss: 0.6214 - val_acc: 0.6949\n",
      "Epoch 7/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.3871 - acc: 0.8315 - val_loss: 0.5971 - val_acc: 0.7299\n",
      "Epoch 8/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.3342 - acc: 0.8604 - val_loss: 0.4717 - val_acc: 0.7912\n",
      "Epoch 9/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.2956 - acc: 0.8782 - val_loss: 0.4485 - val_acc: 0.8117\n",
      "Epoch 10/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.2606 - acc: 0.8950 - val_loss: 0.5818 - val_acc: 0.7723\n",
      "Epoch 11/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.2315 - acc: 0.9090 - val_loss: 0.6058 - val_acc: 0.7707\n",
      "Epoch 12/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.2129 - acc: 0.9191 - val_loss: 0.3593 - val_acc: 0.8589\n",
      "Epoch 13/30\n",
      "21250/21250 [==============================] - 1s 67us/step - loss: 0.1904 - acc: 0.9273 - val_loss: 0.4376 - val_acc: 0.8395\n",
      "Epoch 14/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.1722 - acc: 0.9356 - val_loss: 0.4584 - val_acc: 0.8371\n",
      "Epoch 15/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.1544 - acc: 0.9433 - val_loss: 0.3681 - val_acc: 0.8643\n",
      "Epoch 16/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.1402 - acc: 0.9480 - val_loss: 0.6529 - val_acc: 0.7867\n",
      "Epoch 17/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.1259 - acc: 0.9540 - val_loss: 0.5740 - val_acc: 0.8187\n",
      "Epoch 18/30\n",
      "21250/21250 [==============================] - 1s 69us/step - loss: 0.1146 - acc: 0.9595 - val_loss: 0.4918 - val_acc: 0.8435\n",
      "Epoch 19/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.1018 - acc: 0.9642 - val_loss: 0.4275 - val_acc: 0.8600\n",
      "Epoch 20/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0920 - acc: 0.9684 - val_loss: 0.4487 - val_acc: 0.8597\n",
      "Epoch 21/30\n",
      "21250/21250 [==============================] - 1s 69us/step - loss: 0.0818 - acc: 0.9722 - val_loss: 0.5470 - val_acc: 0.8403\n",
      "Epoch 22/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0748 - acc: 0.9740 - val_loss: 0.4573 - val_acc: 0.8629\n",
      "Epoch 23/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0677 - acc: 0.9776 - val_loss: 0.4645 - val_acc: 0.8637\n",
      "Epoch 24/30\n",
      "21250/21250 [==============================] - 1s 70us/step - loss: 0.0602 - acc: 0.9800 - val_loss: 0.5169 - val_acc: 0.8611\n",
      "Epoch 25/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0532 - acc: 0.9825 - val_loss: 0.9239 - val_acc: 0.8003\n",
      "Epoch 26/30\n",
      "21250/21250 [==============================] - 1s 69us/step - loss: 0.0503 - acc: 0.9834 - val_loss: 0.5723 - val_acc: 0.8531\n",
      "Epoch 27/30\n",
      "21250/21250 [==============================] - 1s 69us/step - loss: 0.0417 - acc: 0.9869 - val_loss: 0.6603 - val_acc: 0.8435\n",
      "Epoch 28/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0376 - acc: 0.9880 - val_loss: 0.5968 - val_acc: 0.8613\n",
      "Epoch 29/30\n",
      "21250/21250 [==============================] - 1s 68us/step - loss: 0.0325 - acc: 0.9901 - val_loss: 0.8090 - val_acc: 0.8251\n",
      "Epoch 30/30\n",
      "21250/21250 [==============================] - 1s 69us/step - loss: 0.0306 - acc: 0.9904 - val_loss: 0.6682 - val_acc: 0.8547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f5461dd2cf8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sentences_encoded_padded, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 68us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7341040785074234, 0.8327199816703796]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:09, 44084.14it/s]\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = 'data/glove.6b/'\n",
    "GLOVE_EMBEDDING_DIM = 100\n",
    "\n",
    "unk_word_embedding = np.zeros(GLOVE_EMBEDDING_DIM)\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_DIR + f'glove.6B.{GLOVE_EMBEDDING_DIM}d.txt') as glove_file:\n",
    "    for i, line in tqdm(enumerate(glove_file)):\n",
    "        word, *word_embedding = line.split()\n",
    "        word_embedding = np.array(word_embedding, dtype='float32')\n",
    "        embeddings_index[word] = word_embedding\n",
    "        unk_word_embedding += word_embedding\n",
    "    unk_word_embedding = unk_word_embedding / i\n",
    "\n",
    "embedding_matrix = np.zeros((len(vocab_encode_dict), GLOVE_EMBEDDING_DIM))\n",
    "for word, i in vocab_encode_dict.items():\n",
    "    embedding_vector = embeddings_index.get(word, unk_word_embedding)\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекурентная сеть с предобученныи эмбедингом Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, None, 100)         8952700   \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, None, 256)         175872    \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 256)               295680    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,498,301\n",
      "Trainable params: 545,601\n",
      "Non-trainable params: 8,952,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    x = input_ = layers.Input((None,))\n",
    "    \n",
    "    x = layers.Embedding(len(vocab_encode_dict), GLOVE_EMBEDDING_DIM)(x)\n",
    "#     x = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(128, return_sequences=True, activation='relu'))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(128, activation='relu'))(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "model.compile(optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) # lr=1e-4\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.6867 - accuracy: 0.5349 - val_loss: 0.6504 - val_accuracy: 0.6291\n",
      "Epoch 2/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.5600 - accuracy: 0.7153 - val_loss: 0.6616 - val_accuracy: 0.7171\n",
      "Epoch 3/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.4457 - accuracy: 0.8089 - val_loss: 0.4386 - val_accuracy: 0.8016\n",
      "Epoch 4/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.3810 - accuracy: 0.8414 - val_loss: 0.4102 - val_accuracy: 0.8136\n",
      "Epoch 5/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.3415 - accuracy: 0.8596 - val_loss: 0.3800 - val_accuracy: 0.8381\n",
      "Epoch 6/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.3173 - accuracy: 0.8714 - val_loss: 0.3290 - val_accuracy: 0.8581\n",
      "Epoch 7/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.2950 - accuracy: 0.8829 - val_loss: 0.3012 - val_accuracy: 0.8773\n",
      "Epoch 8/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.2752 - accuracy: 0.8923 - val_loss: 0.3887 - val_accuracy: 0.8101\n",
      "Epoch 9/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.2805 - accuracy: 0.8864 - val_loss: 0.3903 - val_accuracy: 0.8293\n",
      "Epoch 10/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.2618 - accuracy: 0.8966 - val_loss: 0.2886 - val_accuracy: 0.8768\n",
      "Epoch 11/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.2324 - accuracy: 0.9119 - val_loss: 0.5071 - val_accuracy: 0.7923\n",
      "Epoch 12/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.2318 - accuracy: 0.9118 - val_loss: 0.2791 - val_accuracy: 0.8907\n",
      "Epoch 13/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.2069 - accuracy: 0.9214 - val_loss: 0.2831 - val_accuracy: 0.8923\n",
      "Epoch 14/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.1892 - accuracy: 0.9296 - val_loss: 0.3126 - val_accuracy: 0.8773\n",
      "Epoch 15/20\n",
      "21250/21250 [==============================] - 80s 4ms/step - loss: 0.1774 - accuracy: 0.9345 - val_loss: 0.4090 - val_accuracy: 0.8555\n",
      "Epoch 16/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.1735 - accuracy: 0.9328 - val_loss: 0.2896 - val_accuracy: 0.8893\n",
      "Epoch 17/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.1578 - accuracy: 0.9427 - val_loss: 0.4454 - val_accuracy: 0.8365\n",
      "Epoch 18/20\n",
      "21250/21250 [==============================] - 81s 4ms/step - loss: 0.1468 - accuracy: 0.9442 - val_loss: 0.3749 - val_accuracy: 0.8797\n",
      "Epoch 19/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.1129 - accuracy: 0.9584 - val_loss: 0.3498 - val_accuracy: 0.8864\n",
      "Epoch 20/20\n",
      "21250/21250 [==============================] - 82s 4ms/step - loss: 0.1054 - accuracy: 0.9625 - val_loss: 0.4037 - val_accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f04c2eaefd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sentences_encoded_padded, train_labels,\n",
    "    epochs=20,  # 8 + 4 + 6\n",
    "    batch_size=256,\n",
    "    validation_split=0.15,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 183s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3951938766169548, 0.8788800239562988]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная сеть  с предобученныи эмбедингом Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 500, 100)          8952700   \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 494, 128)          89728     \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 488, 128)          114816    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 69, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 63, 256)           229632    \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 57, 256)           459008    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,108,285\n",
      "Trainable params: 1,155,585\n",
      "Non-trainable params: 8,952,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    x = input_ = layers.Input((500,))\n",
    "    \n",
    "    x = layers.Embedding(len(vocab_encode_dict), GLOVE_EMBEDDING_DIM)(x)\n",
    "    \n",
    "    x = layers.Conv1D(128, 7, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, 7, activation='relu')(x)\n",
    "    x = layers.MaxPool1D(7)(x)\n",
    "    \n",
    "    x = layers.Conv1D(256, 7, activation='relu')(x)\n",
    "    x = layers.Conv1D(256, 7, activation='relu')(x)\n",
    "    x = layers.MaxPool1D(7)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "        \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.35)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])  # Adam()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/30\n",
      "21250/21250 [==============================] - 6s 276us/step - loss: 0.6918 - acc: 0.5288 - val_loss: 0.6700 - val_acc: 0.5880\n",
      "Epoch 2/30\n",
      "21250/21250 [==============================] - 6s 264us/step - loss: 0.6540 - acc: 0.6174 - val_loss: 1.0156 - val_acc: 0.4893\n",
      "Epoch 3/30\n",
      "21250/21250 [==============================] - 6s 264us/step - loss: 0.6147 - acc: 0.6705 - val_loss: 1.1474 - val_acc: 0.4896\n",
      "Epoch 4/30\n",
      "21250/21250 [==============================] - 6s 264us/step - loss: 0.5876 - acc: 0.6996 - val_loss: 1.0485 - val_acc: 0.4997\n",
      "Epoch 5/30\n",
      "21250/21250 [==============================] - 6s 264us/step - loss: 0.5615 - acc: 0.7173 - val_loss: 0.7101 - val_acc: 0.6144\n",
      "Epoch 6/30\n",
      "21250/21250 [==============================] - 6s 265us/step - loss: 0.5387 - acc: 0.7363 - val_loss: 0.4965 - val_acc: 0.7589\n",
      "Epoch 7/30\n",
      "21250/21250 [==============================] - 6s 265us/step - loss: 0.5199 - acc: 0.7491 - val_loss: 0.8523 - val_acc: 0.5893\n",
      "Epoch 8/30\n",
      "21250/21250 [==============================] - 6s 265us/step - loss: 0.5072 - acc: 0.7591 - val_loss: 0.4801 - val_acc: 0.7680\n",
      "Epoch 9/30\n",
      "21250/21250 [==============================] - 6s 265us/step - loss: 0.4952 - acc: 0.7667 - val_loss: 0.6164 - val_acc: 0.6827\n",
      "Epoch 10/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4887 - acc: 0.7699 - val_loss: 0.6302 - val_acc: 0.6872\n",
      "Epoch 11/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4786 - acc: 0.7755 - val_loss: 0.5900 - val_acc: 0.7013\n",
      "Epoch 12/30\n",
      "21250/21250 [==============================] - 6s 267us/step - loss: 0.4643 - acc: 0.7817 - val_loss: 0.6200 - val_acc: 0.6776\n",
      "Epoch 13/30\n",
      "21250/21250 [==============================] - 6s 267us/step - loss: 0.4510 - acc: 0.7923 - val_loss: 0.5947 - val_acc: 0.6981\n",
      "Epoch 14/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4475 - acc: 0.7952 - val_loss: 0.7842 - val_acc: 0.6352\n",
      "Epoch 15/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4342 - acc: 0.8051 - val_loss: 0.5156 - val_acc: 0.7581\n",
      "Epoch 16/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4188 - acc: 0.8112 - val_loss: 0.4572 - val_acc: 0.7968\n",
      "Epoch 17/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4141 - acc: 0.8118 - val_loss: 0.7931 - val_acc: 0.6493\n",
      "Epoch 18/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.4025 - acc: 0.8212 - val_loss: 0.4178 - val_acc: 0.8157\n",
      "Epoch 19/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3960 - acc: 0.8270 - val_loss: 1.3974 - val_acc: 0.5520\n",
      "Epoch 20/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3919 - acc: 0.8271 - val_loss: 0.4515 - val_acc: 0.7867\n",
      "Epoch 21/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3717 - acc: 0.8376 - val_loss: 0.4069 - val_acc: 0.8109\n",
      "Epoch 22/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3649 - acc: 0.8407 - val_loss: 0.3562 - val_acc: 0.8437\n",
      "Epoch 23/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3542 - acc: 0.8476 - val_loss: 0.4438 - val_acc: 0.7979\n",
      "Epoch 24/30\n",
      "21250/21250 [==============================] - 6s 265us/step - loss: 0.3479 - acc: 0.8488 - val_loss: 0.4336 - val_acc: 0.8149\n",
      "Epoch 25/30\n",
      "21250/21250 [==============================] - 6s 267us/step - loss: 0.3398 - acc: 0.8530 - val_loss: 0.6250 - val_acc: 0.7485\n",
      "Epoch 26/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3276 - acc: 0.8625 - val_loss: 0.4127 - val_acc: 0.8248\n",
      "Epoch 27/30\n",
      "21250/21250 [==============================] - 6s 267us/step - loss: 0.3181 - acc: 0.8658 - val_loss: 0.5204 - val_acc: 0.7699\n",
      "Epoch 28/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3097 - acc: 0.8697 - val_loss: 0.4040 - val_acc: 0.8248\n",
      "Epoch 29/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.3007 - acc: 0.8731 - val_loss: 0.5514 - val_acc: 0.7629\n",
      "Epoch 30/30\n",
      "21250/21250 [==============================] - 6s 266us/step - loss: 0.2901 - acc: 0.8795 - val_loss: 0.3359 - val_acc: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f27d1818780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sentences_encoded_padded, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34823826424121856, 0.8514800071716309]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepMoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/ataleckij/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/home/ataleckij/.local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/ataleckij/.ipython',\n",
       " '/home/ataleckij/Projects/university/MO_4sem/laba7/deepmoji',\n",
       " '/home/ataleckij/Projects/university/MO_4sem/laba7/deepmoji/deepmoji']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.pop()\n",
    "sys.path.append('/home/ataleckij/Projects/university/MO_4sem/laba7/deepmoji')\n",
    "sys.path.append('/home/ataleckij/Projects/university/MO_4sem/laba7/deepmoji/deepmoji')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"DeepMoji\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 256)     12800000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 500, 256)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 500, 1024)    3149824     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 500, 1024)    6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 2304)    0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 64)           147520      attlayer[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,395,200\n",
      "Trainable params: 22,395,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from deepmoji.model_def import deepmoji_emojis\n",
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "st = SentenceTokenizer(vocabulary, maxlen)\n",
    "\n",
    "model = deepmoji_emojis(maxlen, PRETRAINED_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_tokenized, _, _ = st.tokenize_sentences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict(test_sentences_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  5,  8,  9, 11, 12, 13, 14, 16, 19, 21, 22, 24, 25, 27, 28,\n",
       "       30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepMoji\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 256)     22918912    input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 500, 256)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 500, 1024)    3149824     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 500, 1024)    6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 500, 2304)    0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 1)            2305        attlayer[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 32,368,897\n",
      "Trainable params: 32,368,897\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from deepmoji.model_def import deepmoji_architecture\n",
    "\n",
    "nb_tokens = len(vocab_encode_dict)#20000\n",
    "# maxlen = 250\n",
    "batch_size = 32\n",
    "\n",
    "model = deepmoji_architecture(nb_classes=2, nb_tokens=nb_tokens, maxlen=maxlen)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# train_labels_cat = to_categorical(train_labels, num_classes=2, dtype='float32')\n",
    "# test_labels_cat = to_categorical(test_labels, num_classes=2, dtype='float32')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/2\n",
      "21250/21250 [==============================] - 1124s 53ms/step - loss: 0.3935 - accuracy: 0.8260 - val_loss: 0.3020 - val_accuracy: 0.8813\n",
      "Epoch 2/2\n",
      "21250/21250 [==============================] - 1126s 53ms/step - loss: 0.2098 - accuracy: 0.9277 - val_loss: 0.3095 - val_accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb768d4edd8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_encoded_padded, train_labels, \n",
    "          batch_size=batch_size, epochs=2,\n",
    "          validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 311s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34343218544244764, 0.8657199740409851]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sentences_encoded_padded, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
