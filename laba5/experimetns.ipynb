{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import enjoyml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.decomposition import PCA\n",
    "# from joblib import dump, load\n",
    "\n",
    "# from data_engineering import read_data, get_filter_duplicates_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "set_session(tf.Session(config=config))\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Dense, Dropout, Flatten, GlobalMaxPool2D\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.optimizers import Adam\n",
    "from enjoyml.keras.layers import FixedPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers, callbacks, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/train/'\n",
    "DATAFLOW_PATH = 'data/train_flow/'\n",
    "enjoyml.path.make_dir_if_not_exist(DATAFLOW_PATH)\n",
    "enjoyml.path.make_dir_if_not_exist(DATAFLOW_PATH + 'cat')\n",
    "enjoyml.path.make_dir_if_not_exist(DATAFLOW_PATH + 'dog')\n",
    "\n",
    "for img_name in tqdm(os.listdir(DATA_PATH)):\n",
    "    label, img_number, img_format = img_name.split('.')\n",
    "    new_file_path = f'{DATAFLOW_PATH + label}/{img_number}.{img_format}'\n",
    "    shutil.copy(DATA_PATH + img_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indixes, val_indexes = train_test_split(np.arange(work_features_matrix.shape[0]), \n",
    "#                                               test_size=0.07, stratify=work_labels, random_state=42)\n",
    "# # train_indixes, val_indexes = train_test_split(np.arange(work_features_matrix.shape[0]), \n",
    "# #                                               test_size=0.50, stratify=work_labels, random_state=42)\n",
    "\n",
    "# print(train_indixes.shape, val_indexes.shape)\n",
    "\n",
    "# fc_model_full = get_fc_model(28)\n",
    "\n",
    "# fc_model_full.compile(loss='sparse_categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# lr_reducer = callbacks.ReduceLROnPlateau(monitor='loss', factor=5e-2, patience=3, \n",
    "#                                          min_lr=1e-15, min_delta=0.03, verbose=1)\n",
    "# stopper = callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=10, \n",
    "#                                   verbose=1, restore_best_weights=True)\n",
    "\n",
    "# fc_model_full.fit(work_features_matrix/255, work_labels_encoded,\n",
    "#                   batch_size=256, epochs=150,\n",
    "#                   callbacks=[lr_reducer, stopper])\n",
    "\n",
    "# fc_model.fit(train_features_matrix/255, train_labels_encoded,\n",
    "#              batch_size=256, epochs=150,\n",
    "#              validation_data=(val_features_matrix/255, val_labels_encoded),\n",
    "#              callbacks=[lr_reducer, stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомная сверточная сеть, без аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256#150\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 2\n",
    "N_EPOCHS = 40\n",
    "\n",
    "IMAGES_TOTAL_COUNT = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 85, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 85, 85, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 85, 85, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,376,145\n",
      "Trainable params: 1,376,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    input_ = x = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "#     x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "#     x = Flatten()(x)\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=input_, outputs=output)\n",
    "\n",
    "model = get_model()\n",
    "model.compile('Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enjoyml.multiclass import calc_class_weights\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "    rescale=1/255.,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "\n",
    "datagen = ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=5e-2, patience=3, \n",
    "                                         min_lr=1e-15, min_delta=0.03, verbose=1)\n",
    "stopper = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, \n",
    "                                  verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "176/176 [==============================] - 69s 393ms/step - loss: 0.6627 - accuracy: 0.5666 - val_loss: 0.3420 - val_accuracy: 0.6639\n",
      "Epoch 2/40\n",
      "176/176 [==============================] - 59s 333ms/step - loss: 0.5659 - accuracy: 0.6952 - val_loss: 0.7568 - val_accuracy: 0.7530\n",
      "Epoch 3/40\n",
      "176/176 [==============================] - 58s 331ms/step - loss: 0.4247 - accuracy: 0.7996 - val_loss: 0.1449 - val_accuracy: 0.8245\n",
      "Epoch 4/40\n",
      "176/176 [==============================] - 58s 327ms/step - loss: 0.3233 - accuracy: 0.8597 - val_loss: 0.1187 - val_accuracy: 0.8637\n",
      "Epoch 5/40\n",
      "176/176 [==============================] - 58s 327ms/step - loss: 0.2613 - accuracy: 0.8898 - val_loss: 0.0141 - val_accuracy: 0.8789\n",
      "Epoch 6/40\n",
      "176/176 [==============================] - 58s 328ms/step - loss: 0.2164 - accuracy: 0.9098 - val_loss: 2.9066 - val_accuracy: 0.9025\n",
      "Epoch 7/40\n",
      "176/176 [==============================] - 58s 329ms/step - loss: 0.1810 - accuracy: 0.9280 - val_loss: 0.0013 - val_accuracy: 0.9093\n",
      "Epoch 8/40\n",
      "176/176 [==============================] - 58s 329ms/step - loss: 0.1510 - accuracy: 0.9391 - val_loss: 0.1640 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 9/40\n",
      "176/176 [==============================] - 58s 328ms/step - loss: 0.1024 - accuracy: 0.9618 - val_loss: 1.1061 - val_accuracy: 0.9177\n",
      "Epoch 10/40\n",
      "176/176 [==============================] - 61s 349ms/step - loss: 0.0804 - accuracy: 0.9696 - val_loss: 1.9387e-04 - val_accuracy: 0.9201\n",
      "Epoch 11/40\n",
      "176/176 [==============================] - 59s 335ms/step - loss: 0.0703 - accuracy: 0.9744 - val_loss: 0.0149 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
      "Epoch 12/40\n",
      "176/176 [==============================] - 58s 331ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.0015 - val_accuracy: 0.9221\n",
      "Epoch 13/40\n",
      "176/176 [==============================] - 57s 323ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0020 - val_accuracy: 0.9197\n",
      "Epoch 14/40\n",
      "176/176 [==============================] - 58s 330ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 0.0040 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
      "Epoch 15/40\n",
      "176/176 [==============================] - 58s 327ms/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 9.6336e-05 - val_accuracy: 0.9217\n",
      "Epoch 16/40\n",
      "176/176 [==============================] - 58s 327ms/step - loss: 0.0583 - accuracy: 0.9802 - val_loss: 0.0011 - val_accuracy: 0.9225\n",
      "Epoch 17/40\n",
      "176/176 [==============================] - 58s 327ms/step - loss: 0.0590 - accuracy: 0.9806 - val_loss: 0.0028 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
      "Epoch 18/40\n",
      "176/176 [==============================] - 58s 328ms/step - loss: 0.0592 - accuracy: 0.9796 - val_loss: 0.2667 - val_accuracy: 0.9205\n",
      "Epoch 19/40\n",
      "176/176 [==============================] - 58s 329ms/step - loss: 0.0583 - accuracy: 0.9804 - val_loss: 4.9125e-07 - val_accuracy: 0.9209\n",
      "Epoch 20/40\n",
      "  9/176 [>.............................] - ETA: 49s - loss: 0.0516 - accuracy: 0.9852"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a79ffd981df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     ),\n\u001b[1;32m     24\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_STEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * (1 - VALIDATION_SPLIT)/TRAIN_BATCH_SIZE) + 1\n",
    "VAL_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * VALIDATION_SPLIT/VAL_BATCH_SIZE) + 1\n",
    "\n",
    "model.fit_generator(\n",
    "    datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "    epochs=N_EPOCHS,\n",
    "#     class_weight=calc_class_weights(train_labels1),\n",
    "    validation_data=datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=VAL_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    callbacks=[lr_reducer, stopper], \n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [03:10<00:00, 65.58it/s]\n"
     ]
    }
   ],
   "source": [
    "DATATEST_PATH = 'data/test/'\n",
    "test_samples, test_labels = [], []\n",
    "\n",
    "for img_name in tqdm(os.listdir(DATATEST_PATH)):\n",
    "    img = imread(DATATEST_PATH + img_name)\n",
    "    img = resize(img, (IMG_SIZE, IMG_SIZE))  # scales to 0..1\n",
    "    sample = img_name.split('.')[0]\n",
    "    label = model.predict(img[np.newaxis, :, :, :])[0][0]\n",
    "    test_samples.append(sample), test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': test_samples, 'label': test_labels}).to_csv('submission_0.csv', index=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомная сверточная сеть, с аугментацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150#150\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 2\n",
    "N_EPOCHS = 40\n",
    "\n",
    "IMAGES_TOTAL_COUNT = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 850,753\n",
      "Trainable params: 850,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    input_ = x = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "#     x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "#     x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "#     x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "#     x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "#     x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "#     x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D((5, 5))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "#     x = GlobalMaxPool2D()(x)\n",
    "\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=input_, outputs=output)\n",
    "\n",
    "model = get_model()\n",
    "model.compile('Adam',#Adam(1e-5),#\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enjoyml.multiclass import calc_class_weights\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=0.025,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.95, 1.05],\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "lr_reducer = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=5e-2, patience=3, \n",
    "                                         min_lr=1e-15, min_delta=0.05, verbose=1)\n",
    "stopper = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, \n",
    "                                  verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "176/176 [==============================] - 120s 681ms/step - loss: 0.6672 - accuracy: 0.5858 - val_loss: 0.8838 - val_accuracy: 0.6531\n",
      "Epoch 2/40\n",
      "176/176 [==============================] - 113s 641ms/step - loss: 0.5987 - accuracy: 0.6808 - val_loss: 0.6893 - val_accuracy: 0.7530\n",
      "Epoch 3/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.5174 - accuracy: 0.7459 - val_loss: 0.6341 - val_accuracy: 0.7766\n",
      "Epoch 4/40\n",
      "176/176 [==============================] - 113s 643ms/step - loss: 0.4428 - accuracy: 0.7973 - val_loss: 0.0366 - val_accuracy: 0.8385\n",
      "Epoch 5/40\n",
      "176/176 [==============================] - 113s 641ms/step - loss: 0.3668 - accuracy: 0.8385 - val_loss: 0.1268 - val_accuracy: 0.8641\n",
      "Epoch 6/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.3120 - accuracy: 0.8639 - val_loss: 1.3925 - val_accuracy: 0.8693\n",
      "Epoch 7/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.2705 - accuracy: 0.8869 - val_loss: 0.0686 - val_accuracy: 0.8969\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 8/40\n",
      "176/176 [==============================] - 113s 643ms/step - loss: 0.2132 - accuracy: 0.9109 - val_loss: 0.2163 - val_accuracy: 0.9177\n",
      "Epoch 9/40\n",
      "176/176 [==============================] - 112s 639ms/step - loss: 0.1993 - accuracy: 0.9166 - val_loss: 0.0051 - val_accuracy: 0.9117\n",
      "Epoch 10/40\n",
      "176/176 [==============================] - 113s 639ms/step - loss: 0.1930 - accuracy: 0.9198 - val_loss: 0.0294 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
      "Epoch 11/40\n",
      "176/176 [==============================] - 113s 640ms/step - loss: 0.1886 - accuracy: 0.9228 - val_loss: 0.2122 - val_accuracy: 0.9129\n",
      "Epoch 12/40\n",
      "176/176 [==============================] - 113s 640ms/step - loss: 0.1849 - accuracy: 0.9252 - val_loss: 0.0069 - val_accuracy: 0.9193\n",
      "Epoch 13/40\n",
      "176/176 [==============================] - 115s 653ms/step - loss: 0.1880 - accuracy: 0.9243 - val_loss: 6.5981e-04 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
      "Epoch 14/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.1863 - accuracy: 0.9222 - val_loss: 0.0572 - val_accuracy: 0.9113\n",
      "Epoch 15/40\n",
      "176/176 [==============================] - 113s 640ms/step - loss: 0.1854 - accuracy: 0.9252 - val_loss: 0.4219 - val_accuracy: 0.9165\n",
      "Epoch 16/40\n",
      "176/176 [==============================] - 113s 643ms/step - loss: 0.1823 - accuracy: 0.9257 - val_loss: 0.0876 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
      "Epoch 17/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.1844 - accuracy: 0.9229 - val_loss: 0.1413 - val_accuracy: 0.9197\n",
      "Epoch 18/40\n",
      "176/176 [==============================] - 113s 641ms/step - loss: 0.1876 - accuracy: 0.9220 - val_loss: 0.0184 - val_accuracy: 0.9173\n",
      "Epoch 19/40\n",
      "176/176 [==============================] - 113s 642ms/step - loss: 0.1876 - accuracy: 0.9230 - val_loss: 0.1960 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.1250002585636594e-10.\n",
      "Epoch 20/40\n",
      " 49/176 [=======>......................] - ETA: 1:02 - loss: 0.1819 - accuracy: 0.9244"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a79ffd981df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     ),\n\u001b[1;32m     24\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_STEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * (1 - VALIDATION_SPLIT)/TRAIN_BATCH_SIZE) + 1\n",
    "VAL_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * VALIDATION_SPLIT/VAL_BATCH_SIZE) + 1\n",
    "\n",
    "model.fit_generator(\n",
    "    datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "    epochs=N_EPOCHS,\n",
    "#     class_weight=calc_class_weights(train_labels1),\n",
    "    validation_data=datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=VAL_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    callbacks=[lr_reducer, stopper], \n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:49<00:00, 73.56it/s]\n"
     ]
    }
   ],
   "source": [
    "DATATEST_PATH = 'data/test/'\n",
    "test_samples, test_labels = [], []\n",
    "\n",
    "for img_name in tqdm(os.listdir(DATATEST_PATH)):\n",
    "    img = imread(DATATEST_PATH + img_name)\n",
    "    img = resize(img, (IMG_SIZE, IMG_SIZE))  # scales to 0..1\n",
    "    sample = img_name.split('.')[0]\n",
    "    label = model.predict(img[np.newaxis, :, :, :])[0][0]\n",
    "    test_samples.append(sample), test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': test_samples, 'label': test_labels}).to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дообучение resnet сеть, с аугментацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256#150\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 2\n",
    "N_EPOCHS = 20\n",
    "\n",
    "IMAGES_TOTAL_COUNT = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NET = True\n",
    "\n",
    "resnet_conv_base = ResNet50V2(\n",
    "    include_top=False, \n",
    "    weights='imagenet' if IMAGE_NET else None, \n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")  # imagenet\n",
    "\n",
    "\n",
    "def get_resnet_model():\n",
    "    input_ = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    x = resnet_conv_base(input_)\n",
    "\n",
    "#     x = Flatten()(x)\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "#     x = Dense(1024, activation='relu')(x)\n",
    "#     x = Dropout(0.35)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_, outputs=output)\n",
    "    \n",
    "#     for layer in model.layers[1].layers[:-22]:\n",
    "    for layer in model.layers[1].layers[:-37]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "resnet_model = get_resnet_model()\n",
    "if IMAGE_NET:\n",
    "    #sparse_categorical_crossentropy\n",
    "    resnet_model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    resnet_model.compile('Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_conv_base.layers[:-22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Model)           (None, 8, 8, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 28,285,953\n",
      "Trainable params: 19,692,033\n",
      "Non-trainable params: 8,593,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enjoyml.multiclass import calc_class_weights\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=0.05,\n",
    "    width_shift_range=0.125,\n",
    "    height_shift_range=0.125,\n",
    "    zoom_range=[0.95, 1.05],\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=5e-2, patience=3, \n",
    "                                         min_lr=1e-15, min_delta=0.01, verbose=1)\n",
    "stopper = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, \n",
    "                                  verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/ataleckij/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "176/176 [==============================] - 274s 2s/step - loss: 1.1897 - accuracy: 0.8079 - val_loss: 0.0331 - val_accuracy: 0.9564\n",
      "Epoch 2/20\n",
      "176/176 [==============================] - 247s 1s/step - loss: 0.4072 - accuracy: 0.9240 - val_loss: 0.0446 - val_accuracy: 0.9680\n",
      "Epoch 3/20\n",
      "176/176 [==============================] - 247s 1s/step - loss: 0.2668 - accuracy: 0.9464 - val_loss: 1.4051e-07 - val_accuracy: 0.9732\n",
      "Epoch 4/20\n",
      "176/176 [==============================] - 248s 1s/step - loss: 0.2039 - accuracy: 0.9552 - val_loss: 2.6742e-07 - val_accuracy: 0.9764\n",
      "Epoch 5/20\n",
      "176/176 [==============================] - 248s 1s/step - loss: 0.1825 - accuracy: 0.9606 - val_loss: 2.1377e-08 - val_accuracy: 0.9756\n",
      "Epoch 6/20\n",
      "176/176 [==============================] - 247s 1s/step - loss: 0.1461 - accuracy: 0.9670 - val_loss: 9.6922e-05 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-07.\n",
      "Epoch 7/20\n",
      "176/176 [==============================] - 248s 1s/step - loss: 0.1281 - accuracy: 0.9686 - val_loss: 0.0100 - val_accuracy: 0.9780\n",
      "Epoch 8/20\n",
      "176/176 [==============================] - 249s 1s/step - loss: 0.1261 - accuracy: 0.9672 - val_loss: 2.7031 - val_accuracy: 0.9792\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f06de86c278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * (1 - VALIDATION_SPLIT)/TRAIN_BATCH_SIZE) + 1\n",
    "VAL_STEPS_PER_EPOCH = int(IMAGES_TOTAL_COUNT * VALIDATION_SPLIT/VAL_BATCH_SIZE) + 1\n",
    "\n",
    "resnet_model.fit_generator(\n",
    "    datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "    epochs=N_EPOCHS,\n",
    "#     class_weight=calc_class_weights(train_labels1),\n",
    "    validation_data=datagen.flow_from_directory(\n",
    "        DATAFLOW_PATH,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=VAL_BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    callbacks=[lr_reducer, stopper], \n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.save('resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "resnet_model = load_model('resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [05:31<00:00, 37.72it/s]\n"
     ]
    }
   ],
   "source": [
    "DATATEST_PATH = 'data/test/'\n",
    "test_samples, test_labels = [], []\n",
    "\n",
    "for img_name in tqdm(os.listdir(DATATEST_PATH)):\n",
    "    img = imread(DATATEST_PATH + img_name)\n",
    "    img = resize(img, (IMG_SIZE, IMG_SIZE))  # scales to 0..1\n",
    "    sample = img_name.split('.')[0]\n",
    "    label = resnet_model.predict(img[np.newaxis, :, :, :])[0][0]\n",
    "    test_samples.append(sample), test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': test_samples, 'label': test_labels}).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvIAAABZCAIAAADTvVcfAAAWV0lEQVR4Ae2dP0gjzRvH7VJaWlpaWlpaWqbcMmXKlJaWQkCCIMRC2OKKBQsXBBkOohtE3HAe7kG4W+49cAgiy4ncyovcHqcwP56Z/TMbk80pvj/PzVdecLO7M/M8n4nvfu/5k8wI/IAACIAACIAACIBAKQjMlMILOAECIAACIAACIAACArIGbwIQAAEQAAEQAIGSEICsKclGwg0QAAEQAAEQAAHIGrwHQAAEQAAEQAAESkIAsqYkGwk3QAAEQAAEQAAEIGvwHgABEAABEAABECgJAciakmwk3AABEAABEAABEICswXsABEAABEAABECgJAQga0qykXADBEAABEAABEAAsgbvARAAARAAARAAgZIQgKwpyUbCDRAAARAAARAAAcgavAdAAARAAARAAARKQgCypiQbCTdAAARAAARAAAQga/AeAAEQAAEQAAEQKAmBF5U1t3yp2an2H57J5i4wtrpL3dunDve6vbmtT/bdU8fhfhAAARAAgf+QAHfaaw3DMIz6aovxaNxKEWet1bphGLXGWtsJ9NsiztprjRpdWm1ZXqhfo+PQs9ZqRtVouUNXCpYOPVstZzTWiswamrEsLwvI6C6+3U35m2RNdLNq9QzvyfKEe5+Wra/O2D8ZfadwDAIgAAIg8P8gELrrtarRaDHHYe1Vo2qssUeqhOwI2JpRra21mePYrYZRrbXc5D55yWi0bMdh5lrdMBqmn5keeuZqrWrUHsuaoqW51TCM+rrluC5rr9XGmpWtU6ajIjK6n295U/4mWaMzxTEIgAAIgMAbJsDNRtVYc2KFErmtWrXW1kRJ4ppHF1pu/O/SkDROw+Lyqt+uV2vrySUR2KtGNqMQ7np9zXQDbjWGojVFS8s5W168Oi1nrI6WW4mBZfpdREb3801vygRZE30f1N6dzG10KhvHyweX/j057ndPKxufbHksxIO9d1TZ+UbvVpWEOrte3z2ZbR7NbX9c/eenIkVDtvqm11/aOqpsnKx0b/j3y5p5PNs8mjc/2yrvdB8Yzc5SV0VrfrLD88Wto0rzaG7nfP3il5pnsj33d/b7jzRwo7vwrm9e/ZYDf7XfdSq7A3b4cWFTGnB4nQt0qtnJhev13d78xhH5u8+TP6cHv/95ZbtbaXZmt3rG2S39oX7/utg8WvFiw8T9dW2zM79/g5hRyhIHIAAC00sgsBuGkUkSIbyWUa2bSq9oWJTMyORO5JDQsOl/0CEdpsJICCEfylm6KQrl/28fyZrCpf123ain8ipy16dJ1hSSKc2mFMqa+5v6VmfunW9d/HD6n5c2OouHJECKZc3c5unK4aXVHzTedWeaJ6tXVGpDQ5pHC7tfrX+u23snUqx8XO9fM4+mnd29IqGgyRp+9qHSPDHOAmdw3do9rmyeW3dCTLbnl713PLNxWutd2V8GdbM7s/HBJJNJ1syQMhvYF9ft/dPZZtf4ohSPtpX3PxrbncrWx3UvsM8+L292Zq1L+uOSCmbx4JINbuzuh7nmcf3iQYh/13c6FetS/Vskuugn57UJcQgCIAAC00mAVEwSdZEEHj1S5VmlYvRwCTfr1ZoKp7g0R6aESIOMyBk9kjXFS1MSqrZm+2EYBm67YYzLjZVx24rJpB6/8U0plDV3gxUKn/yrnA1v74I/iNZkEYuIAhize0EkZc1M84OpAjFy2sV42ge2d1TZ/kohQU3WuAfHM5ufbBX6uP/Fb6UEmWjPLV9udpZ6SXXO3WV1o7Pw/kcsa9QqtNANRVYObtJNjB3sn88mOoz+pXDxrX4wcO9F9OXTbPOkMVCl0L+Dm59Kykh5d26RkQ/OwXFl67MTR7CGJsZLEAABEJgyAiRBGjLoEjsu8z167EWef3xWUykyc2Wsmm4QRiFn6w3DqD5OGWkD1FKTluZsrVZVP0a9laTJpmF/JpEZu1Ua479/Uwpljfhp7R1XKE90Xj/k9lWccCmO1lT7aRTkt7XbUfmp3JDocqXZWT6L81POfrey7VMVuyZroquvSxudyubpyt7nde/Gj1M7k+z5h/TH6lX69vxJuad3g0BGa9LIihC3q9ud2f3r9D514L4/ntnsO0NnhRDRTX37aGaju2T1G70r5zZp9br5ttQ8oqiPDCPNk37CDwiAAAiAgBAy0hLXyEgeo6M1MtGUK27RojVCRL5sdCINYjRajj2UlZITa49cBb5w6YCt1Yz6mul4vu+y1qph1LMS5bJvXCGZzPk3vinFskYI8du/uGy971d3upXm0XKPIjc5jfK4tkaXNdYzZQ3xvbu1z77W9z4sbHQqWf92oT0vIWvYyIjL/U+3z1f3z5e2jmY2ThsDJd3uWiaFo8KBv0DhnOxdgSMQAAEQmGoCUmzotTX0SB1ZW0MVw0kJb1xQo2prEn5RyHlAMXLKHz2e4pGsKVraN+u5+uLpqhkuIpPQpt9++y1vSqGsiX66F2mkRJan7FC2iPd6lTSjpEpMtJLhuf3rOLYik1Bze/Qyp4QmR2segu8/2FUczokGn+ebR9UvD2KMPdnkN/TBOVoS6kpPQk2M1oT9j5RsksVA1HV48a22L5NQt7fOhSwTpshNYGx05pIEFqHY/LR6cBIHnPQ3Bo5BAARAYHoJUNQlK/iVjcW6fEnByBap0Z1Q3F6tN9pe/EQRfruhVfumEzySNaJgaaou0c0gWZOvAUrnLeNBAZmcu296UwplzQ1f3ujM736zL26YRyW0c3tSMlNwojNvfTX7l+t7vfnNOCSjOqHmtvSS4dOsZDhtnvoDWePsH89s9BretXMRtHZPKs3T9e9CjLEnkzUiVzLckCXDbSqhkZ1QSXlvLgl1O1jZPFKl0OL+JisZ9vy0ZDikmpvuyuGVc3FtHX6cpwaoWHKJ28Fys1NpdhZkMXXufYEXIAACIDDFBEKHPhWm0bIZs1vqc2viBlROndqrLH5FfdvV2mqbMWbJz61ZTz+3hm6kS2qKWrX2qDZHxXByARjVQzVm6chr16uUhGKuRx9cQ3allkzBZk3DphTKGiGCf75Wd7qzzU5l82R5f5Co5t9u73xhk06uHF6buQbvI8O7WbeSBu8vWoP3E2SNENGtuf9hYbMz0zya3zlPG8VH2qPJGiHu76z3Hxepi/tRg/doWXNZ1T/amBq8T+dlQ/vSXtrg/cvpfaLWdNXg3fuhSobln8DP9rsjavj6PgV/EHARBEAABJ5AgD6olj5Eb/hThqm+pbaWyBohQj/+lGGDPmU41wMe+vEnAssPIM5dSgx5HK2huPqYpeUHE9st+cHFhlFvrLULPv04WaFUv8eRKc+mTJA1pdpNOAMCIAACIAACIFBqApA1pd5eOAcCIAACIAAC00QAsmaadhu+ggAIgAAIgECpCUDWlHp74RwIgAAIgAAITBMByJpp2m34CgIgAAIgAAKlJgBZU+rthXMgAAIgAAIgME0EIGumabfhKwiAAAiAAAiUmgBkTam3F86BAAiAAAiAwDQRgKyZpt2GryAAAiAAAiBQagKQNaXeXjgHAiAAAiAAAtNEALJmmnYbvoIACIAACIBAqQlMkDWhZ5vZD/OTb1KNmXDHzH9/x9/PKvKZnX6P2tPM/W3vdSsmH/mtJPpM/Au3vj/oZ3AMAiAAAiAAAiDwfyAwQdYErlX0PWBTJWuiK2O7t7zTa9FXghf8PLC9brX/u+AOXAIBEAABEAABEPgvCEyQNZxZTvzl8aNWJ1nj+Y5tmaZlO37yxdYR95g6x7xABXgiziw3mSlwLBnkiTizHc9llmV7IX2Lq2Nb9GM7PJkqXTXiLrMty7Qs5qZX6aRlmqbNPN+17diAMD5r2Y6XLJnN4zPb8ROb46m4o6m30LWlOekQdRD2zxff//B7H5a6/8aX7gYr25/WDz8ubnXntnoN+XXlzvsT+sLzje787iUtHt2293rzG0ezW73a2a2C4RycrLznNfNkfrO7sMu9+6Gl8BIEQAAEQAAEQOA5BIplTejZli0Vimkzlw+loITgjmnGyiX0mKWSVDSIKYUR+sxSYmOcrDEtJ5429GzbkSIo4q5DMkf/CVwWy6bIZ0oUCX0hj1mmWolUiZozCjy6NW915LPMZu4oQSV4LLTUl9aPUjW/TOt09bsQt4OVna+eMu1usLJxbPR/RkKEF58Xt/oOCRQ9WvPb3jtePLgO7kV0e13fOa79Q1Ec5+B41vzqRkLc37Wt7vLZT91VHIMACIAACIAACDyPQLGsESHnPCRdEAWuHSsUbSE9CZUUrZA8yURJ8mqcrMlCOEqkxMEdbY2hwyhMtEgytbqBzpKWorRZVgIUOPorujNTRfSK5pCVNqmuyc+aLn47WDG/+fTyl7V7unolL9wNVrb6LI613NS3PrRv87ImuqpunluJrgr753O7V5GUNcu9WMoEZx/mDyaktVIrcAACIAACIAACIFBAYIKs0UcGrmVngkFeycmaOM1ESkKrqo3TWJNljRAhd2UWigJDQ8EaQREc27ZtxhzHViGW/EIkR0jWkD7JMk+hr2sssjlRX7FnqZyJD8aoGn7WqzQ7M8l/8+9/0HiSNZ+deKYfje1HsuaGL2/7bnyDEAN/QVYcOwfHK0mEJvA+zu9D1qSMcAACIAACIAACzydQLGuigGfhkz+UNXlhkL7Sa2sSNZTTOpkPaTwmO5VEaOhMMmW+BiZIojW5+Ew+dkOjKQmVdW/RXHFflNQ1oc+0UFO6/l3L7K2n2iO6qm5/pnzTRFkzKloTymgNZE0KFwcgAAIgAAIg8FIEimUNJYZUSUtEtTOqeEVbOtEndCrVKNkgkdXWUHIoLnmhmZSySIfQ+MC1mUpeRUlCKVuJREt60TbVcejaVlxcLOccrq0RVFsz3Mg1uraGVqK6YTYc3JEm3HxbSutp6MQv0zquXzyMkTVUOrN4+COk5NSvcbU1kDXZ5uIIBEAABEAABF6IQLGskYkh2Wtk2WlTk7bySFlDCoe6lqg7ShsUBbJriTqmvKwTKqutkaMs6mvSm6qSxSLu0oymxVwv61QK07NP6oRyedIJlWu5ogLoUbEar3u6oLJOiTX87MP8/nU0Olojou8DY6c7+05+wg11Qp0+6oRCEipBid8gAAIgAAIg8HIEJsmal1vpP54pdG2tVPhZiyXZrWcNxiAQAAEQAAEQAIHXJvCWZU3oM+aq2p+IO7YW+HkOVZpiVKzmOXNhDAiAAAiAAAiAwCsQeMuyRojAkx8FODpv9RSagWOZVlza85RxuBcEQAAEQAAEQODvIfC2Zc3fwxGWgAAIgAAIgAAIvDoByJpX3wIYAAIgAAIgAAIg8DIEIGtehiNmAQEQAAEQAAEQeHUCkDWvvgUwAARAAARAAARA4GUIQNa8DEfMAgIgAAIgAAIg8OoEIGtefQtgAAiAAAiAAAiAwMsQgKx5GY6YBQRAAARAAARA4NUJQNa8+hbAABAAARAAARAAgZchAFnzMhwxCwiAAAiAAAiAwKsTgKx59S2AASAAAiAAAiAAAi9DALLmZThiFhAAARAAARAAgVcnAFnz6lsAA0AABEAABEAABF6GAGTNy3DELCAAAiAAAiAAAq9OALLm1bcABoAACIAACIAACLwMgZeRNZyZth+NsCh0bcsJRlx40inumLYXPmlIdnPo2dbTRz9vVLbqmKPIt02Hj7n4lNMRdyxLzRT5zGQj6T9lQtwLAiAAAiAAAm+fQPllTRT4rh+M0lxFu/e8UUUzymt/JGtC7w+0T8g9j0upB1kzETtuAAEQAAEQmBIC5Zc1f9VGvpysydyCrMlY4AgEQAAEQGC6CUySNRH3HNuyTNO0mONriaCQu8w2TdO0HT/wtSRUFNAIGmC7nI9LQoW+usm07GTaocdz4Fq2qxaUSSjOk2mTAUKoC540xLIdHkaBx+Ti6axCnzYio8k202ZeFsGZZIzmEnNViITeNWr12BHyVsOjvauS2clAngvEKLgSVTpv4JB56idO30nUsdXpIoFrWa5M7/2Bg5o1OAQBEAABEACB8hIoljWUDpFqQQgSDGb8IBUicCyTnuNRFIZKbsS1NaHPTMvxA7qiJMao2prAsSylK6LQY3Hpi/54FkLkZQ3JHy+Z1UpqSbhjmpYjBUrIHUtqLNIWUeDaSTlONi0dSaOFkEbHRS6TjFEQlEvcY1TSolJacvVYHsnlR1S4yBoY5klSgVJASW1N4NqWuhKFJP9spVKEyCehpCuEWkSh5tYoWTPGwfK+e+EZCIAACIAACOQIFMua3K0iLQyO6Eir4ZUiRxat0sM2eWyTvPBtc4SsGR6vlsn0h3w9JGtYrCVo1nR57mRKS0qttDw5kwbZtGHeuNi5bDbd22wU1eYmgkO6lPqeW31IjMRzkRma2KG14pLhiDNL84mGJ6Qy23WL5HHo2yaTJcejZM1oBx9NghMgAAIgAAIgUFICE2VNGHDfcx2H2ZS9UWIme6QqKlIZkKzJxECMSz5oH3dCyWiKaTPH9XiQpG6GBudlja6iMgWRa5HKWZVJA23a0GcWhX0cz6foR/xTbEw2UeJSmkfKrS4lnKbo1N35W/RATODKtFKSb5K/YwH0eMmAe67cAxqjxFDm7UQHE0fxGwRAAARAAARKTqBY1sikB3M9zoMgDP2kzzp7pCo642UN3ZlGUPIoIxJMrkNCg8miHe3xTHdSbkivrUnUj9DEQU415KzKpMHQtJGSaTYl0TK9Nd6YbKLY/OxEbvVnyBrKZuV/1BLZCjI0Rfk+x/U5D8Iw9FiRrKHxox2MjccvEAABEAABECgzgUJZkxMK8rmtgibDeRsqa1G1NRSD0EIW9IAeKWsiLVhCFS8yo5Xmlgg4raHJmlwqJxuRCC0akbM2kwaarInCTBtplo4yJhtVmITSgkgjm5zIjLFJqFwiLwqDhElme1KXnJot55PpuMzbzFQxxsEyv4HhGwiAAAiAAAhkBAplDT0wZcVwFIVULJskofIlw77DrETWCL1kmMuupBGyhh7OybyBKsIli+i0Re1MUUjVtaYua6yhkmFVaZOLl2QPej2goyXGSKAwWXccUclwrCpGG6NpBXXD6JLhSbJGPCoZzmQfCSuiEFdXZ6XIUtHJC7EjqjibCotpD8YnoUY7mG02jkAABEAABECg3AQKZQ11DCVt3MzlaRKKkCRXqEE7IHmRfM5t1g3NXB5khbA5jlnPctbgTZPG3dI2czl39AZvRovEfeNDDd5JKGOirBEi7kWi5nPmpjXIo4zRZI3sAkvWThuxHwVSRkZrJKm0Bdzh1AqfRbPSBm+tzV1iijmoOxMoJOz4hCTUaAdz6PECBEAABEAABEpLYIKsKa3fcAwEQAAEQAAEQKB0BCBrSrelcAgEQAAEQAAEppUAZM207jz8BgEQAAEQAIHSEYCsKd2WwiEQAAEQAAEQmFYCkDXTuvPwGwRAAARAAARKRwCypnRbCodAAARAAARAYFoJQNZM687DbxAAARAAARAoHQHImtJtKRwCARAAARAAgWklAFkzrTsPv0EABEAABECgdAQga0q3pXAIBEAABEAABKaVAGTNtO48/AYBEAABEACB0hGArCndlsIhEAABEAABEJhWApA107rz8BsEQAAEQAAESkcAsqZ0WwqHQAAEQAAEQGBaCUDWTOvOw28QAAEQAAEQKB2B/wGhKJqCQXp1HQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
