{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymatreader import read_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] True\n"
     ]
    }
   ],
   "source": [
    "# tf.config.gpu.set_per_process_memory_fraction(0.80)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4*1024)])\n",
    "\n",
    "# tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "print(tf.config.experimental.list_physical_devices('GPU'), tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [[2.]]\n",
    "# m = tf.matmul(x, x)\n",
    "# print(\"hello, {}\".format(m))\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(mat_bboxes):\n",
    "    labels = []\n",
    "    for bbox in mat_bboxes:\n",
    "        if type(bbox['label']) is list:\n",
    "            label = ''.join([str(int(value)) for value in bbox['label']])\n",
    "        else:\n",
    "            label = str(int(bbox['label']))\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def convert_to_csv(set_type):\n",
    "    mat = read_mat(f'data/{set_type}/digitStruct.mat')\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'img_names': mat['digitStruct']['name'], \n",
    "        'labels': extract_labels(mat['digitStruct']['bbox'])\n",
    "    })\n",
    "    df.to_csv(f'data/{set_type}.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = convert_to_csv('train')\n",
    "# df_test = convert_to_csv('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lens = df_train['labels'].astype(str).map(lambda s: len(s)).values\n",
    "plt.hist(train_lens, bins=list(range(10)))\n",
    "print(train_lens.max())\n",
    "plt.show()\n",
    "\n",
    "test_lens = df_test['labels'].astype(str).map(lambda s: len(s)).values\n",
    "plt.hist(test_lens, bins=list(range(10)))\n",
    "print(test_lens.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBERS = 4#7\n",
    "IMAGES_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33402, 2), (13068, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32756, 2), (12961, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train['labels'].astype(str).map(lambda s: len(s)) <= MAX_NUMBERS]\n",
    "df_test = df_test[df_test['labels'].astype(str).map(lambda s: len(s)) <= MAX_NUMBERS]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label, max_numbers=MAX_NUMBERS):\n",
    "    len_ = len(label)\n",
    "    len_encoding = np.zeros(max_numbers)\n",
    "    len_encoding[len_ - 1] = 1\n",
    "    len_encoding = len_encoding[:, np.newaxis]\n",
    "    \n",
    "    numbers_encoding = np.zeros((max_numbers, 10))\n",
    "    numbers_encoding[np.arange(len_), np.asarray(list(label)).astype(int)] = 1\n",
    "    return np.hstack((len_encoding, numbers_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(max_numbers=MAX_NUMBERS, size=IMAGES_SIZE):\n",
    "    input_ = x = tf.keras.layers.Input((size, size, 3))\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    len_prediction = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    len_prediction = tf.keras.layers.Dense(max_numbers, activation='softmax')(len_prediction)\n",
    "#     if sparse:\n",
    "#         len_prediction = tf.keras.backend.argmax(len_prediction, axis=-1) + 1\n",
    "    len_prediction = tf.keras.backend.expand_dims(len_prediction, axis=-1)\n",
    "        \n",
    "    numbers_predictions = []\n",
    "    for _ in range(max_numbers):\n",
    "        ni_pred = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "        ni_pred = tf.keras.layers.Dense(10, activation='softmax')(ni_pred)\n",
    "#         if sparse:\n",
    "#             ni_pred = tf.keras.backend.argmax(ni_pred, axis=-1)\n",
    "        ni_pred = tf.keras.backend.expand_dims(ni_pred, axis=1)\n",
    "        numbers_predictions.append(ni_pred)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([*numbers_predictions], axis=1)\n",
    "    output = tf.keras.layers.concatenate([len_prediction, output], axis=-1)\n",
    "    return tf.keras.models.Model(input_, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32768)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          16777728    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           1290        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           1290        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           1290        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           1290        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            516         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 10)]      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 1, 10)]      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 1, 10)]      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 1, 10)]      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 4, 1)]       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 10)        0           tf_op_layer_ExpandDims_1[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 11)        0           tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 17,398,732\n",
      "Trainable params: 17,398,732\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = model.predict(np.random.randint(0, 255, (5, IMAGES_SIZE, IMAGES_SIZE, 3)))\n",
    "x2 = x1.copy()\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_X_generator():\n",
    "#     while True:\n",
    "#         for img_name in df_train['img_names'].values:\n",
    "#             img = imread(f'data/train/{img_name}')\n",
    "#             yield resize(img, (IMAGES_SIZE, IMAGES_SIZE))\n",
    "                         \n",
    "# def get_train_Y_generator():\n",
    "#     while True:\n",
    "#         for label in df_train['labels'].astype(str).values:\n",
    "#             yield encode_label(label)\n",
    "                         \n",
    "# # train_X = np.asarray([resize(imread(f'data/train/{img_name}'), (IMAGES_SIZE, IMAGES_SIZE)) \n",
    "# #                       for img_name in tqdm(df_train['img_names'].values)])\n",
    "# # train_Y = np.asarray([encode_label(label)\n",
    "# #                       for label in tqdm(df_train['labels'].astype(str).values)])\n",
    "\n",
    "# train_X_gen = get_train_X_generator()\n",
    "# train_Y_gen = get_train_Y_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(df, dir_name, batch_size):\n",
    "    while True:\n",
    "        images, labels = [], []\n",
    "        for i, (img_name, label) in enumerate(df[['img_names', 'labels']].values):\n",
    "            img = imread(f'data/{dir_name}/{img_name}')\n",
    "            pad_size = max(img.shape[:2])\n",
    "            pad_img = np.zeros((pad_size, pad_size, 3))\n",
    "            pad_img[:img.shape[0], :img.shape[1]] = img\n",
    "            images.append(resize(pad_img, (IMAGES_SIZE, IMAGES_SIZE)))  # devide 255\n",
    "            labels.append(encode_label(str(label)))\n",
    "            if ((i + 1) % 16 == 0 and i != 0) or (i + 1) == df.shape[0] - 1:\n",
    "                yield np.asarray(images), np.asarray(labels)\n",
    "                images, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_generator(df_train, 'train', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImagesAccesor:\n",
    "#     def __init__(self, df):\n",
    "#         self.images_names = df['img_names'].values\n",
    "\n",
    "# #     def __next__(self):\n",
    "# #         for img_name in self.data_frame['img_names'].values:\n",
    "# #             img = imread(f'data/train/{img_name}')\n",
    "# #             yield resize(img, (IMAGES_SIZE, IMAGES_SIZE))\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         print(0)\n",
    "#         img_name = self.images_names[index]\n",
    "#         img = imread(f'data/train/{img_name}')\n",
    "#         return resize(img, (IMAGES_SIZE, IMAGES_SIZE))\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.images_names.shape[0]\n",
    "\n",
    "\n",
    "# class LabelsAccesor:\n",
    "#     def __init__(self, df):\n",
    "#         self.labels = df['labels'].astype(str).values\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         print(1)\n",
    "#         return encode_label(self.labels[index])\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_loss(y_true, y_pred):\n",
    "    true_len = y_true[:, :, 0]\n",
    "    pred_len = y_pred[:, :, 0]\n",
    "    len_loss = true_len * tf.math.log(pred_len + tf.keras.backend.epsilon())\n",
    "\n",
    "    true_numbers = y_true[:, :, 1:]\n",
    "    pred_numbers = y_pred[:, :, 1:]\n",
    "    numbers_loss = true_numbers * tf.math.log(pred_numbers + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return tf.concat((-0.8 * tf.expand_dims(len_loss, axis=-1), \n",
    "                      -1.2 * numbers_loss), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_mask(len_, max_numbers=MAX_NUMBERS):\n",
    "    return tf.cast(tf.range(MAX_NUMBERS) < len_, tf.int32)\n",
    "\n",
    "def numbers_acc(y_true, y_pred, weights=[0.3, 0.7]):\n",
    "    true_len = y_true[:, :, 0]\n",
    "    pred_len = y_pred[:, :, 0]\n",
    "    sparse_true_len = tf.argmax(true_len, axis=-1) + 1  # +1 because of length\n",
    "    len_acc = tf.cast(tf.equal(sparse_true_len, tf.argmax(pred_len, axis=-1) + 1), tf.float32)\n",
    "\n",
    "    true_numbers = y_true[:, :, 1:]\n",
    "    pred_numbers = y_pred[:, :, 1:]\n",
    "    numbers_acc = tf.cast(tf.equal(tf.argmax(true_numbers, axis=-1), \n",
    "                                   tf.argmax(pred_numbers, axis=-1)), tf.float32)\n",
    "    len_mask = tf.map_fn(get_len_mask, tf.cast(sparse_true_len, tf.int32))\n",
    "    numbers_acc = tf.boolean_mask(numbers_acc, len_mask)\n",
    "    \n",
    "    return weights[0] * tf.reduce_mean(len_acc) + weights[1] * tf.reduce_mean(numbers_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ataleckij/Projects/university/MO_4sem/laba4/py3_env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1340: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=910, shape=(), dtype=float32, numpy=0.7>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_acc(encode_label('211')[np.newaxis, :, :], \n",
    "            encode_label('2110')[np.newaxis, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "409/409 [==============================] - 45s 111ms/step - loss: 0.1582 - numbers_acc: 0.3329 - val_loss: 0.1505 - val_numbers_acc: 0.3325\n",
      "Epoch 2/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1499 - numbers_acc: 0.3343 - val_loss: 0.1499 - val_numbers_acc: 0.3438\n",
      "Epoch 3/50\n",
      "409/409 [==============================] - 42s 104ms/step - loss: 0.1492 - numbers_acc: 0.3432 - val_loss: 0.1496 - val_numbers_acc: 0.3448\n",
      "Epoch 4/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1495 - numbers_acc: 0.3464 - val_loss: 0.1493 - val_numbers_acc: 0.3452\n",
      "Epoch 5/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.1499 - numbers_acc: 0.3482 - val_loss: 0.1492 - val_numbers_acc: 0.3459\n",
      "Epoch 6/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1490 - numbers_acc: 0.3411 - val_loss: 0.1495 - val_numbers_acc: 0.3440\n",
      "Epoch 7/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.1485 - numbers_acc: 0.3453 - val_loss: 0.1493 - val_numbers_acc: 0.3453\n",
      "Epoch 8/50\n",
      "409/409 [==============================] - 43s 104ms/step - loss: 0.1492 - numbers_acc: 0.3470 - val_loss: 0.1492 - val_numbers_acc: 0.3451\n",
      "Epoch 9/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1497 - numbers_acc: 0.3491 - val_loss: 0.1493 - val_numbers_acc: 0.3459\n",
      "Epoch 10/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.1476 - numbers_acc: 0.3488 - val_loss: 0.1455 - val_numbers_acc: 0.3734\n",
      "Epoch 11/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1419 - numbers_acc: 0.3828 - val_loss: 0.1361 - val_numbers_acc: 0.4146\n",
      "Epoch 12/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.1301 - numbers_acc: 0.4355 - val_loss: 0.1194 - val_numbers_acc: 0.4831\n",
      "Epoch 13/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.1201 - numbers_acc: 0.4822 - val_loss: 0.1071 - val_numbers_acc: 0.5408\n",
      "Epoch 14/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1125 - numbers_acc: 0.5110 - val_loss: 0.1026 - val_numbers_acc: 0.5669\n",
      "Epoch 15/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1062 - numbers_acc: 0.5443 - val_loss: 0.0988 - val_numbers_acc: 0.5804\n",
      "Epoch 16/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.1020 - numbers_acc: 0.5651 - val_loss: 0.0926 - val_numbers_acc: 0.6149\n",
      "Epoch 17/50\n",
      "409/409 [==============================] - 44s 108ms/step - loss: 0.0970 - numbers_acc: 0.5934 - val_loss: 0.0897 - val_numbers_acc: 0.6292\n",
      "Epoch 18/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.0938 - numbers_acc: 0.6034 - val_loss: 0.0888 - val_numbers_acc: 0.6334\n",
      "Epoch 19/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0898 - numbers_acc: 0.6156 - val_loss: 0.0844 - val_numbers_acc: 0.6486\n",
      "Epoch 20/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.0887 - numbers_acc: 0.6260 - val_loss: 0.0807 - val_numbers_acc: 0.6664\n",
      "Epoch 21/50\n",
      "409/409 [==============================] - 45s 109ms/step - loss: 0.0858 - numbers_acc: 0.6473 - val_loss: 0.0789 - val_numbers_acc: 0.6769\n",
      "Epoch 22/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0833 - numbers_acc: 0.6466 - val_loss: 0.0793 - val_numbers_acc: 0.6806\n",
      "Epoch 23/50\n",
      "409/409 [==============================] - 42s 103ms/step - loss: 0.0800 - numbers_acc: 0.6655 - val_loss: 0.0750 - val_numbers_acc: 0.6927\n",
      "Epoch 24/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0800 - numbers_acc: 0.6640 - val_loss: 0.0742 - val_numbers_acc: 0.6968\n",
      "Epoch 25/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0781 - numbers_acc: 0.6801 - val_loss: 0.0723 - val_numbers_acc: 0.7062\n",
      "Epoch 26/50\n",
      "409/409 [==============================] - 42s 104ms/step - loss: 0.0769 - numbers_acc: 0.6774 - val_loss: 0.0756 - val_numbers_acc: 0.6939\n",
      "Epoch 27/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0734 - numbers_acc: 0.6898 - val_loss: 0.0705 - val_numbers_acc: 0.7114\n",
      "Epoch 28/50\n",
      "409/409 [==============================] - 42s 104ms/step - loss: 0.0738 - numbers_acc: 0.6909 - val_loss: 0.0714 - val_numbers_acc: 0.7089\n",
      "Epoch 29/50\n",
      "409/409 [==============================] - 43s 105ms/step - loss: 0.0728 - numbers_acc: 0.7015 - val_loss: 0.0707 - val_numbers_acc: 0.7085\n",
      "Epoch 30/50\n",
      "409/409 [==============================] - 44s 108ms/step - loss: 0.0713 - numbers_acc: 0.7012 - val_loss: 0.0714 - val_numbers_acc: 0.7107\n",
      "Epoch 31/50\n",
      "409/409 [==============================] - 44s 108ms/step - loss: 0.0682 - numbers_acc: 0.7159 - val_loss: 0.0681 - val_numbers_acc: 0.7202\n",
      "Epoch 32/50\n",
      "409/409 [==============================] - 43s 104ms/step - loss: 0.0687 - numbers_acc: 0.7114 - val_loss: 0.0687 - val_numbers_acc: 0.7171\n",
      "Epoch 33/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0669 - numbers_acc: 0.7254 - val_loss: 0.0676 - val_numbers_acc: 0.7214\n",
      "Epoch 34/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0664 - numbers_acc: 0.7188 - val_loss: 0.0685 - val_numbers_acc: 0.7201\n",
      "Epoch 35/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0635 - numbers_acc: 0.7295 - val_loss: 0.0674 - val_numbers_acc: 0.7232\n",
      "Epoch 36/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0646 - numbers_acc: 0.7302 - val_loss: 0.0719 - val_numbers_acc: 0.7050\n",
      "Epoch 37/50\n",
      "409/409 [==============================] - 45s 110ms/step - loss: 0.0633 - numbers_acc: 0.7359 - val_loss: 0.0660 - val_numbers_acc: 0.7297\n",
      "Epoch 38/50\n",
      "409/409 [==============================] - 44s 106ms/step - loss: 0.0630 - numbers_acc: 0.7333 - val_loss: 0.0662 - val_numbers_acc: 0.7285\n",
      "Epoch 39/50\n",
      "409/409 [==============================] - 44s 106ms/step - loss: 0.0610 - numbers_acc: 0.7434 - val_loss: 0.0661 - val_numbers_acc: 0.7324\n",
      "Epoch 40/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0603 - numbers_acc: 0.7502 - val_loss: 0.0659 - val_numbers_acc: 0.7319\n",
      "Epoch 41/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0588 - numbers_acc: 0.7551 - val_loss: 0.0668 - val_numbers_acc: 0.7274\n",
      "Epoch 42/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0589 - numbers_acc: 0.7551 - val_loss: 0.0682 - val_numbers_acc: 0.7227\n",
      "Epoch 43/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0572 - numbers_acc: 0.7612 - val_loss: 0.0647 - val_numbers_acc: 0.7371\n",
      "Epoch 44/50\n",
      "409/409 [==============================] - 44s 108ms/step - loss: 0.0577 - numbers_acc: 0.7601 - val_loss: 0.0658 - val_numbers_acc: 0.7346\n",
      "Epoch 45/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0561 - numbers_acc: 0.7681 - val_loss: 0.0652 - val_numbers_acc: 0.7353\n",
      "Epoch 46/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0552 - numbers_acc: 0.7676 - val_loss: 0.0666 - val_numbers_acc: 0.7345\n",
      "Epoch 47/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0545 - numbers_acc: 0.7721 - val_loss: 0.0651 - val_numbers_acc: 0.7402\n",
      "Epoch 48/50\n",
      "409/409 [==============================] - 43s 106ms/step - loss: 0.0542 - numbers_acc: 0.7772 - val_loss: 0.0669 - val_numbers_acc: 0.7337\n",
      "Epoch 49/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0531 - numbers_acc: 0.7802 - val_loss: 0.0676 - val_numbers_acc: 0.7283\n",
      "Epoch 50/50\n",
      "409/409 [==============================] - 44s 107ms/step - loss: 0.0529 - numbers_acc: 0.7756 - val_loss: 0.0663 - val_numbers_acc: 0.7342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92dc0d7a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "VAL_BATCH_SIZE = 16\n",
    "\n",
    "# generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "# #     rescale=1/255,\n",
    "#     rotation_range=0.05, \n",
    "#     zoom_range=0.025,\n",
    "#     width_shift_range=0.2, \n",
    "#     height_shift_range=0.2, \n",
    "#     fill_mode=\"nearest\"\n",
    "# )\n",
    "\n",
    "model.compile(loss=numbers_loss, optimizer='adam', metrics=[numbers_acc])\n",
    "\n",
    "model.fit_generator(\n",
    "#     generator.flow(\n",
    "#         ImagesAccesor(df_train), LabelsAccesor(df_train), \n",
    "#         batch_size=BATCH_SIZE\n",
    "#     ),\n",
    "#     validation_split=0.2, \n",
    "    get_generator(df_train.iloc[:int(0.8 * df_train.shape[0])], 'train', BATCH_SIZE),\n",
    "    steps_per_epoch=(0.8 * df_train.shape[0]) // BATCH_SIZE,\n",
    "    validation_data=get_generator(df_train.iloc[-int(0.2 * df_train.shape[0]):], 'train', VAL_BATCH_SIZE),\n",
    "    validation_steps=(0.2 * df_train.shape[0]) // VAL_BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
